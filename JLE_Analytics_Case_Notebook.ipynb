{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1128a8a",
   "metadata": {},
   "source": [
    "# JLE Supplier Quality, Retention, and Learning-Curve Analysis\n",
    "**Author:** Ivanna Nguyen  \n",
    "\n",
    "**Goal:** Recreate and extend the Excel-based case analysis in Python. We will:\n",
    "- clean the three worksheets in the provided Excel file,\n",
    "- build models (trend/counterfactual, multiple regression, and learning curve),\n",
    "- visualize results, and\n",
    "- export clean tables and charts for a portfolio/GitHub repo.\n",
    "\n",
    "> This notebook mirrors a \"clean → analyze → visualize\" pattern similar to common portfolio examples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac4ff3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- setup: imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from pathlib import Path\n",
    "\n",
    "# plotting rule of thumb for portfolios: one chart per cell, no specific colors\n",
    "plt.rcParams['figure.figsize'] = (10,6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cfabef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- locate Excel file (choose the first one that exists)\n",
    "excel_candidates = [\n",
    "    Path('/mnt/data/Chapter 8 Case Data (1).xlsx'),\n",
    "    Path('/mnt/data/Chapter 8 Case Data (2).xlsx'),\n",
    "    Path('data/chapter8_case_data.xlsx'),  # fallback if running from a repo\n",
    "]\n",
    "\n",
    "excel_path = None\n",
    "for p in excel_candidates:\n",
    "    if p.exists():\n",
    "        excel_path = p\n",
    "        break\n",
    "\n",
    "assert excel_path is not None, \"Excel file not found. Update excel_candidates to point to your file.\"\n",
    "excel_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069328f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- inspect sheets\n",
    "xls = pd.ExcelFile(excel_path)\n",
    "xls.sheet_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08179853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick peek at the first few rows from each sheet\n",
    "sheets = {name: pd.read_excel(excel_path, sheet_name=name) for name in xls.sheet_names}\n",
    "for name, df in sheets.items():\n",
    "    print(f\"=== {name} ===\")\n",
    "    print(df.head(), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2ddc7c",
   "metadata": {},
   "source": [
    "## 1) Supplier Defects — Clean, Model, Visualize\n",
    "We tidy the `Defects after Delivery` sheet, fit a pre‑initiative trend, and compare the **actual** path to a **counterfactual** path that assumes the initiative never happened (initiative in **August 2015**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17aabadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_defects(df):\n",
    "    # first visible row contains 'Month, 2014, 2015, 2016, 2017, 2018'\n",
    "    tidy = df.iloc[1:].copy()\n",
    "    cols = ['Month'] + [str(int(x)) for x in df.iloc[0,1:].values if pd.notnull(x)]\n",
    "    tidy.columns = ['Month'] + cols[1:]\n",
    "    # reshape to long format\n",
    "    long_df = tidy.melt(id_vars='Month', var_name='Year', value_name='DefectsPerMillion')\n",
    "    long_df = long_df.dropna(subset=['Month','DefectsPerMillion'])\n",
    "    # month order and time index\n",
    "    month_order = {m:i for i,m in enumerate(\n",
    "        ['January','February','March','April','May','June','July','August','September','October','November','December'], start=1)}\n",
    "    long_df['MonthNum'] = long_df['Month'].map(month_order)\n",
    "    long_df['Year'] = long_df['Year'].astype(int)\n",
    "    long_df = long_df.sort_values(['Year','MonthNum']).reset_index(drop=True)\n",
    "    start_year = long_df['Year'].min()\n",
    "    long_df['t'] = (long_df['Year'] - start_year) * 12 + (long_df['MonthNum'] - 1) + 1\n",
    "    return long_df\n",
    "\n",
    "def analyze_defects(long_df, initiative_year=2015, initiative_month=8):\n",
    "    # compute time index for initiative month\n",
    "    t0 = long_df.loc[(long_df['Year']==initiative_year) & (long_df['MonthNum']==initiative_month), 't'].iloc[0]\n",
    "    pre = long_df[long_df['t'] < t0]\n",
    "    post = long_df[long_df['t'] >= t0]\n",
    "    # fit linear trend on pre period\n",
    "    X_pre = sm.add_constant(pre['t'])\n",
    "    y_pre = pre['DefectsPerMillion']\n",
    "    model = sm.OLS(y_pre, X_pre).fit()\n",
    "    # predict counterfactual for post\n",
    "    X_post = sm.add_constant(post['t'])\n",
    "    post = post.copy()\n",
    "    post['Counterfactual'] = model.predict(X_post)\n",
    "    post['Improvement_vs_CF'] = post['Counterfactual'] - post['DefectsPerMillion']\n",
    "    post['Improvement_pct'] = post['Improvement_vs_CF'] / post['Counterfactual']\n",
    "    return model, t0, pre, post\n",
    "\n",
    "defects_raw = sheets['Defects after Delivery']\n",
    "defects_long = clean_defects(defects_raw)\n",
    "def_model, t0, defects_pre, defects_post = analyze_defects(defects_long)\n",
    "\n",
    "avg_improve = defects_post['Improvement_pct'].mean()\n",
    "avg_improve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25aa1328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot: actual path vs. counterfactual after initiative\n",
    "plt.plot(defects_long['t'], defects_long['DefectsPerMillion'])\n",
    "plt.plot(defects_post['t'], defects_post['Counterfactual'])\n",
    "plt.axvline(t0, linestyle='--')\n",
    "plt.title('supplier defects per million — actual vs pre‑trend counterfactual')\n",
    "plt.xlabel('months since jan 2014')\n",
    "plt.ylabel('defects per million')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60630947",
   "metadata": {},
   "source": [
    "## 2) Employee Retention — Multiple Regression\n",
    "Target: `YearsPLE` (years with company)  \n",
    "\n",
    "Predictors: `YrsEducation`, `College GPA`, `Age`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb884fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret_raw = sheets['Employee Retention'].copy()\n",
    "# header row is at index 1\n",
    "ret_cols = ret_raw.iloc[1].tolist()\n",
    "ret_df = ret_raw.iloc[2:].copy()\n",
    "ret_df.columns = ret_cols\n",
    "ret_df = ret_df[['YearsPLE','YrsEducation','College GPA','Age']].dropna()\n",
    "ret_df = ret_df.astype({'YearsPLE':'float','YrsEducation':'float','College GPA':'float','Age':'float'})\n",
    "\n",
    "X = sm.add_constant(ret_df[['YrsEducation','College GPA','Age']])\n",
    "y = ret_df['YearsPLE']\n",
    "ret_model = sm.OLS(y, X).fit()\n",
    "ret_model.rsquared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f128e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick coefficient table\n",
    "ret_model.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8deaf6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# viz: GPA vs. tenure (simple OLS line for display)\n",
    "plt.scatter(ret_df['College GPA'], ret_df['YearsPLE'])\n",
    "X_gpa = sm.add_constant(ret_df['College GPA'])\n",
    "yhat = sm.OLS(y, X_gpa).fit().predict(X_gpa)\n",
    "plt.plot(ret_df['College GPA'], yhat)\n",
    "plt.title('employee retention vs. college gpa')\n",
    "plt.xlabel('college gpa')\n",
    "plt.ylabel('years with company')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193986ca",
   "metadata": {},
   "source": [
    "## 3) Engine Production — Learning Curve\n",
    "Model: \\( \\log(T) = a + b \\log(N) \\). Learning rate when output doubles = \\(2^b\\)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd084973",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_raw = sheets['Engines'].copy()\n",
    "eng_df = eng_raw.iloc[2:].copy()\n",
    "eng_df.columns = ['Sample','ProductionTimeMin']\n",
    "eng_df = eng_df.dropna()\n",
    "eng_df['Sample'] = eng_df['Sample'].astype(int)\n",
    "eng_df['ProductionTimeMin'] = pd.to_numeric(eng_df['ProductionTimeMin'])\n",
    "\n",
    "eng_df['logN'] = np.log(eng_df['Sample'])\n",
    "eng_df['logT'] = np.log(eng_df['ProductionTimeMin'])\n",
    "X = sm.add_constant(eng_df['logN'])\n",
    "y = eng_df['logT']\n",
    "lc_model = sm.OLS(y, X).fit()\n",
    "\n",
    "b = lc_model.params['logN']\n",
    "learning_rate = float(2 ** b)\n",
    "learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f963fe01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot: learning curve in original units\n",
    "plt.scatter(eng_df['Sample'], eng_df['ProductionTimeMin'])\n",
    "yhat = np.exp(lc_model.predict(X))\n",
    "plt.plot(eng_df['Sample'], yhat)\n",
    "plt.title('engine production learning curve')\n",
    "plt.xlabel('cumulative unit number')\n",
    "plt.ylabel('production time (minutes)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82022d0d",
   "metadata": {},
   "source": [
    "## 4) Export Clean Tables and Visuals\n",
    "These files can be committed to your repository for reviewers to explore alongside the notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00181e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = Path('jle_outputs')\n",
    "out_dir.mkdir(exist_ok=True)\n",
    "\n",
    "defects_post.to_csv(out_dir / 'defects_actual_vs_counterfactual.csv', index=False)\n",
    "ret_df.to_csv(out_dir / 'employee_retention_clean.csv', index=False)\n",
    "eng_df.to_csv(out_dir / 'engines_clean.csv', index=False)\n",
    "\n",
    "# save the three figures again\n",
    "# 1) defects\n",
    "plt.figure()\n",
    "plt.plot(defects_long['t'], defects_long['DefectsPerMillion'])\n",
    "plt.plot(defects_post['t'], defects_post['Counterfactual'])\n",
    "plt.axvline(t0, linestyle='--')\n",
    "plt.title('supplier defects per million — actual vs pre‑trend counterfactual')\n",
    "plt.xlabel('months since jan 2014')\n",
    "plt.ylabel('defects per million')\n",
    "plt.tight_layout()\n",
    "plt.savefig(out_dir / 'defects_actual_vs_counterfactual.png', dpi=220)\n",
    "plt.close()\n",
    "\n",
    "# 2) retention\n",
    "plt.figure()\n",
    "plt.scatter(ret_df['College GPA'], ret_df['YearsPLE'])\n",
    "X_gpa = sm.add_constant(ret_df['College GPA'])\n",
    "yhat = sm.OLS(ret_df['YearsPLE'], X_gpa).fit().predict(X_gpa)\n",
    "plt.plot(ret_df['College GPA'], yhat)\n",
    "plt.title('employee retention vs. college gpa')\n",
    "plt.xlabel('college gpa')\n",
    "plt.ylabel('years with company')\n",
    "plt.tight_layout()\n",
    "plt.savefig(out_dir / 'retention_vs_gpa.png', dpi=220)\n",
    "plt.close()\n",
    "\n",
    "# 3) learning curve\n",
    "plt.figure()\n",
    "plt.scatter(eng_df['Sample'], eng_df['ProductionTimeMin'])\n",
    "yhat = np.exp(lc_model.predict(X))\n",
    "plt.plot(eng_df['Sample'], yhat)\n",
    "plt.title('engine production learning curve')\n",
    "plt.xlabel('cumulative unit number')\n",
    "plt.ylabel('production time (minutes)')\n",
    "plt.tight_layout()\n",
    "plt.savefig(out_dir / 'learning_curve.png', dpi=220)\n",
    "plt.close()\n",
    "\n",
    "summary = f\"\"\"average improvement vs. counterfactual after initiative: {defects_post['Improvement_pct'].mean():.1%}\n",
    "retention model R^2: {ret_model.rsquared:.3f}\n",
    "estimated learning rate (time drop when doubling output): {learning_rate:.3f}\n",
    "\"\"\"\n",
    "with open(out_dir / 'readme_numbers.txt', 'w') as f:\n",
    "    f.write(summary)\n",
    "\n",
    "sorted([p.name for p in out_dir.iterdir()])"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
